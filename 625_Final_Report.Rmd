---
title: "Biostats 625 Final Project - US 2019 Census Data"
author: "Group 4 members: Ting Gong, Lap Sum Chan, Margaret Prentice"
date: "December 20, 2020"
output:
  pdf_document: default
  html_document: default
  rmarkdown::pdf_document:
    fig_caption: yes
    includes: null
subtitle: \textit{https://github.com/Gongting811/625FinalProject}
header-includes:
- \usepackage[utf8]{inputenc}
- \usepackage{listings}
- \usepackage{amsmath}
- \usepackage{bm}
- \usepackage{bbm}
- \usepackage{amssymb}
- \usepackage{graphicx}
- \usepackage{multirow}
- \usepackage{caption}
- \usepackage{color}
- \usepackage{array}
- \usepackage{tabu}
- \usepackage{mathtools}
- \usepackage{bbold}
- \usepackage{array}
- \usepackage{mathrsfs}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include=FALSE}
library(ggplot2)
```

## 1. Introduction

The problem of income inequality has been of great concern in the recent years. Large differences in annual incomes may be the result of a combination of factors such as education level, age, gender, occupation, race, etc. This project aims to conduct a comprehensive analysis to highlight the key factors that are necessary in improving an individual's income. Such analysis would help to set focus on the important areas which can significantly improve the income levels of individuals and thus help to provide a guidance for the individual who wants to make some changes to improve their income level. After identifying the important predictors for income, several binary classifiers are trained to predict whether an individual's annual income in 2019 falls in the income category of either greater than or equal to 60,000 USD or less than 60,000 USD using the dataset extracted from the 2019 Census Bureau database.

## 2. Data Pre-processing

The demographic and income data in this report are from the Current Population Survey (CPS) Annual Social and Economic Supplement (ASEC) conducted by the US Census Bureau in 2019. The US Census Bureau collects data and publishes estimates on income and poverty each year to evaluate national economic trends as well as to understand their impact on the wellbeing of households, families, and individuals. 

***Dataset Extraction***

Our dataset were extracted from the original individual-level ASEC dataset, which contains 180101 individuals and 799 features in total. The biggest challenge was to encode all the categorical variables. Most of the variables are categorical ones, but they were all encoded numerically in the original dataset. Therefore, the first thing we did was to find them all by reading the documentations and encode them in the proper categorical form by hand. Next, we applied several conditions including `income` > 0, `age` > 15 and `age` < 80, `labor force status` == "working", `working hour` > 0 to the dataset. Then, to reduce the dimension and select related features from the raw data, we did the Backward Elimination with `income` variable as the response variable and all the remaining ones as covariates. As a result, a set of features were selected that contains demographic variables such as `age`, `race`, `sex`, `academic degree`, `marital status`, `ethnic`, and `region`; employment variables such as `labor force status`, `working hours`, `worker classes`, `major industry` and `major occupation`; health-related variables such as `total medical expenditures` and `health status`. Finally, we merged similar columns for several categorical variables, dropped all the outliers and eventually got our census19 dataset.

```{r include=FALSE}
census19 = read.table("census19.csv", header=T, sep=',')
```


***Exploratory Data Analysis***

First, we plot a histogram and a boxplot of `age` versus `income level`. We can see from the graphs below that the `age` variable has a wide range and variability, and the percentage of people who make above $60000 peaks out at roughly 35% between ages 35 and 60. The boxplot shows that individuals who have higher incomes tend to be older than those who don't. This implies that `age` might be a good predictor of `income level`.

```{r, echo=FALSE, fig.width = 3.5, fig.height=2}
opar<-par(no.readonly=T); par(mfrow=c(1,2))
ggplot(census19, aes(A_AGE)) + 
  geom_histogram(aes(fill = income_level), color = "black", binwidth = 1) +
  labs(x='Age', title = 'Age vs. Income Level') +
  theme(legend.position="none")
ggplot(aes(x=income_level, y=A_AGE, fill=income_level), data = census19) + 
  geom_boxplot() + 
  labs(x='Income', y='Age') +
  ggtitle('Age vs. Income Level') +
  theme(legend.position="none")
par(opar);
```

Next, we plot a histogram and a boxplot of `working hours` (per week) versus `income level`. It is shown from the graph that the highest frequency of `working hours` (per week) occurs at around 35-45 hours. The boxplot shows that individuals who have higher incomes tend to work longer than those who don't. 


```{r, echo=FALSE, fig.width = 3.5, fig.height=2}
opar<-par(no.readonly=T); par(mfrow=c(1,2))
ggplot(census19, aes(A_USLHRS)) + 
  geom_histogram(aes(fill = income_level), color = "black", binwidth = 10) +
  labs(x='Working Hours', title = 'Working Hours vs. Income Level') +
  theme(legend.position="none")
ggplot(aes(x=income_level, y=A_USLHRS, fill=income_level), data = census19) + 
  geom_boxplot() + 
  labs(x='Income', y='Working Hours') +
  ggtitle('Working Hours vs. Income Level') +
  theme(legend.position="none")
par(opar);
```

After visualizing the distribution of `income level` versus the above two continuous variables `age` and `working hours`, we then explored some categorical variables. It turned out that the following four variables `sex`, `work class`, `academic degree` and `region` are all likely to be good predictors.


```{r, include=FALSE}
levels(census19$A_HGA)[levels(census19$A_HGA)%in% c('Less than 1st grade', '1st,2nd,3rd,or 4th grade', '5th or 6th grade', '7th and 8th grade', '9th grade', '10th grade', '11th grade', '12th grade no diploma', 'High school graduate - high school diploma or equivalent')] = "high school or below"

levels(census19$A_HGA)[levels(census19$A_HGA)%in% c('Some college but no degree', 'Associate degree in college - occupation/vocation program', 'Associate degree in college - academic program')] = "college no degree"

levels(census19$A_HGA)[levels(census19$A_HGA)%in% c('Bachelor\'s degree (for example: BA,AB,BS)')] = "BS degree"

levels(census19$A_HGA)[levels(census19$A_HGA)%in% c('Master\'s degree (for example: MA,MS,MENG,MED,MSW , MBA)', 'Professional school degree (for example: MD,DDS,DVM,LLB,JD)')] = "MS degree"
                      
levels(census19$A_HGA)[levels(census19$A_HGA)%in% c('Doctorate degree (for example: PHD,EDD)')] = "PhD degree" 

```

```{r, echo=FALSE, fig.width = 3.5, fig.height=3}
opar<-par(no.readonly=T); par(mfrow=c(1,2))
ggplot(aes(x=A_CLSWKR), data=census19) + 
  geom_bar(aes(fill = income_level), color = "black", width=0.3) + 
  ggtitle('Workclass with Income Level') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1), legend.position="none") +
  labs(x='Workclass')

ggplot(aes(x=A_SEX), data=census19) + 
  geom_bar(aes(fill = income_level), color = "black", width=0.2) + 
  ggtitle('Sex vs Income Level') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1), legend.position="none") +
  labs(x='Sex')
par(opar);
```
```{r, echo=FALSE, fig.width = 3.5, fig.height=3}
opar<-par(no.readonly=T); par(mfrow=c(1,2))
ggplot(census19, aes(MIG_DIV)) + 
  geom_bar(aes(fill = income_level), color = "black") +
  theme(axis.text.x = element_text(angle = 45, vjust=1)) +
  labs(x='Region', title = 'Regions vs. Income Level') +
  theme(legend.position="none")
ggplot(aes(x=A_HGA), data=census19) + 
  geom_bar(aes(fill = income_level), color = "black", width=0.5) + 
  ggtitle('Academic Degree vs Income Level') + 
  theme(axis.text.x = element_text(angle = 45, vjust = 1), legend.position="none") +
  labs(x='Degree')
par(opar);
```

Lastly, we split the dataset into 60%, 20% and 20% for training, validation and testing respectively after the EDA.
 
## 3. Methodology

**Logistic Regression**

Several models and interaction terms were considered for logistic regression. The final model included all features settled upon during the datast extraction, as well as interaction terms between `sex` and `marital status` and between `worker classes` and `major industry`. These interaction terms were significant and reduced the AIC of the model as well as increased the area under the curve (AUC) of the receiver operating characteristic (ROC) curve as compared to the base logistic regression model with all features and no interaction terms. 

```{r include = FALSE}
library("gridExtra")
library("pROC")
library("precrec")
train <- read.csv("train.csv")
test <- read.csv("test.csv")

earnbin <- rep(0,nrow(train))   ## binning the training response variable
earnbin[which(train$PEARNVAL >= 60000)] <- 1
newtrain <- cbind(train,earnbin)
newtrain$earnbinf <- as.factor(newtrain$earnbin)

newtrain$HEAbin <- NA       ## binning the HEA variable for the training dataset
newtrain$HEAbin[which(newtrain$HEA=="Excellent")] <- "Good"
newtrain$HEAbin[which(newtrain$HEA=="Good")] <- "Good"
newtrain$HEAbin[which(newtrain$HEA=="Very good")] <- "Good"
newtrain$HEAbin[which(newtrain$HEA=="Fair")] <- "Bad"
newtrain$HEAbin[which(newtrain$HEA=="Poor")] <- "Bad"
newtrain$HEAbin <- as.factor(newtrain$HEAbin)
newtrain <- newtrain[,-1]

newtest <- test[,-1]

newtest$HEAbin <- NA       ## binning the HEA variable for the testing dataset
newtest$HEAbin[which(newtest$HEA=="Excellent")] <- "Good"
newtest$HEAbin[which(newtest$HEA=="Good")] <- "Good"
newtest$HEAbin[which(newtest$HEA=="Very good")] <- "Good"
newtest$HEAbin[which(newtest$HEA=="Fair")] <- "Bad"
newtest$HEAbin[which(newtest$HEA=="Poor")] <- "Bad"
newtest$HEAbin <- as.factor(newtest$HEAbin)

newtest$earnbin <- 0   ## binning the test response variable
newtest$earnbin[which(test$PEARNVAL >= 60000)] <- 1
newtest$earnbinf <- as.factor(newtest$earnbin)
newtest <- newtest[,-c(1,14,16)]
## confirming that levels rae defined the same way between datasets
levels(newtest$PRDTRACE) <- levels(newtrain$PRDTRACE)
levels(newtest$A_HGA) <- levels(newtrain$A_HGA)
levels(newtest$A_MARITL) <- levels(newtrain$A_MARITL)
levels(newtest$PEHSPNON) <- levels(newtrain$PEHSPNON)
levels(newtest$MIG_DIV) <- levels(newtrain$MIG_DIV)
levels(newtest$A_CLSWK) <- levels(newtrain$A_CLSWK)
levels(newtest$A_MJIND) <- levels(newtrain$A_MJIND)
levels(newtest$A_MJOCC) <- levels(newtrain$A_MJOCC)
levels(newtest$HEAbin) <- levels(newtrain$HEAbin)
## logistic regression model
binintglm <- glm(earnbin ~ A_AGE + A_SEX + PRDTRACE + A_HGA + A_SEX*A_MARITL + PEHSPNON + MIG_DIV + A_USLHRS + A_CLSWKR*A_MJIND + A_MJIND + A_MJOCC + MOOP + HEAbin, data=newtrain, family="binomial")

## generating predictions from test data
glm.prob.2 = predict(binintglm, newdata = newtest, type = "response")
glm.roc.2 = roc(newtest$earnbinf ~ glm.prob.2)

em1 <- evalmod(scores = glm.prob.2, labels=newtest$earnbinf)
```
The plot below to the left shows the AUC of the ROC curve for the logistic regression model with interaction termsbetween `sex` and `marital status` and between `worker classes` and `major industry`. The plot below to the right shows the AUC of the Precision-Recall (PR) curve for the same logistic regression model. The table below shows the decimal values for each, with about the AUC of the ROC curve being about 79.1% and the AUC of the PR curve being about 59.3%.
```{r echo = FALSE}
## generating AUC ROC and AUC PR % and plots
curves.part1 <- part(em1, xlim = c(0.0, 1))
paucs.df1 <- pauc(curves.part1)
knitr::kable(paucs.df1[,-c(1,2,5)])
autoplot(em1)
```

**Random Forest**

When testing the data under random forest models, models without interaction terms were first considered. These were tested to see the optimal number of features to include. Setting the number of features equal to 6 or higher minimized the number of incorrect predictions in the train dataset. Increasing the number of features to values greater than 6 reduced the AUC of the ROC curve. When applying the random forest models to the test dataset, setting the number of features equal to 2 maximized the AUC of the ROC curve. The difference in AUC of the ROC curve between a random forest with 2 features and random forest with 6 features was about 0.008 or 0.8%. The random forest with 6 features was chosen to balance the number of incorrect features against higher AUC of the ROC curve.

```{r include = FALSE}
library("randomForest")
rf6 <- randomForest(earnbinf ~ A_AGE + PRDTRACE + A_SEX + A_HGA + A_MARITL + PEHSPNON + MIG_DIV + A_USLHRS + A_CLSWKR + A_MJIND + A_MJOCC + MOOP + HEAbin, data=newtrain, mtry=6, importance = T)
rf6.roc = roc(newtrain$earnbinf, rf6$votes[,2], percent=TRUE)
## generating predictions from test data
rf.prob.6 <- predict(rf6, newdata=newtest, type="prob")
em2 <- evalmod(scores = rf.prob.6[,2], labels=newtest$earnbinf)
```
The plot below to the left shows the AUC of the ROC curve for the random forest using 6 features. The plot below to the right shows the AUC of the PR curve for the random forest using 6 features. There was an improvement in both AUC of the ROC curve and the PR curve when using the random forest. The table below shows the decimal values for each, with about the AUC of the ROC curve being about 83.5% and the AUC of the PR curve being about 71.5%. The AUC of the ROC curve increased by about 5.6% while the AUC of the PR curve increased by about 20.5% from the logistic regression model to the random forest.
```{r echo = F}
## generating AUC ROC and AUC PR % and plots
curves.part2 <- part(em2, xlim = c(0.0, 1))
paucs.df2 <- pauc(curves.part2)
knitr::kable(paucs.df2[,-c(1,2,5)])
autoplot(em2)
```

## 4. Result

***Feature Importance***


***Model Comparison***






